<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>WebXR AR Hit-Test demo</title>
  <style>body{margin:0;overflow:hidden}</style>
</head>
<body>
  <script type="module">
    import * as THREE from 'https://unpkg.com/three@0.155.0/build/three.module.js';
    import { ARButton } from 'https://unpkg.com/three@0.155.0/examples/jsm/webxr/ARButton.js';

    // 1. Renderer with XR enabled
    const renderer = new THREE.WebGLRenderer({ antialias:true, alpha:true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.xr.enabled = true;
    document.body.appendChild(renderer.domElement);

    // 2. Scene & camera
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera();

    // 3. Add ARButton (prompts the user for camera permission)
    document.body.appendChild(
      ARButton.createButton(renderer, {requiredFeatures:['hit-test','anchors']})
    );

    // 4. Set up reticle (cursor) to show where placement is possible
    const reticleGeo = new THREE.RingGeometry(0.05,0.06,32).rotateX(-Math.PI/2);
    const reticleMat = new THREE.MeshBasicMaterial({ color:0xffffff });
    const reticle   = new THREE.Mesh(reticleGeo, reticleMat);
    reticle.matrixAutoUpdate = false;
    reticle.visible = false;
    scene.add(reticle);

    // 5. Session refs for hit-test & anchors
    let hitTestSource   = null;
    let localSpace      = null;

    renderer.xr.addEventListener('sessionstart', async () => {
      const session = renderer.xr.getSession();
      localSpace = await session.requestReferenceSpace('viewer');
      hitTestSource = await session.requestHitTestSource({ space: localSpace });

      // Clean-up when the session ends
      session.addEventListener('end', () => {
        hitTestSource = null;
        localSpace    = null;
      });
    });

    // 6. Controller to place object on tap
    const controller = renderer.xr.getController(0);
    controller.addEventListener('select', onSelect);
    scene.add(controller);

    // 6a. Media texture you wanted (video overlay turned into a texture)
    const vid = document.createElement('video');
    vid.src = '/video/123.mp4';   // must be served over https!
    vid.loop = true;
    vid.muted = true;
    await vid.play();          // autoplay is allowed inside XR gesture
    const vidTexture = new THREE.VideoTexture(vid);

    function onSelect() {
      if (!reticle.visible) return;

      // 1Ã—0.6 m plane textured with the video
      const plane = new THREE.Mesh(
        new THREE.PlaneGeometry(1, 0.6),
        new THREE.MeshBasicMaterial({ map: vidTexture, side: THREE.DoubleSide })
      );
      plane.position.setFromMatrixPosition(reticle.matrix);
      plane.quaternion.setFromRotationMatrix(reticle.matrix);
      scene.add(plane);

      // Optional: create anchor so the plane _really_ sticks to world space
      const session = renderer.xr.getSession();
      if (session.createAnchor) {
        session.createAnchor(reticle.matrix, renderer.xr.getReferenceSpace())
               .then(anchor => anchor.context = plane);
      }
    }

    // 7. Render loop with per-frame hit-test
    renderer.setAnimationLoop((timestamp, frame) => {
      if (frame && hitTestSource) {
        const hitTestResults = frame.getHitTestResults(hitTestSource);
        if (hitTestResults.length) {
          const hit = hitTestResults[0];
          const pose = hit.getPose(renderer.xr.getReferenceSpace());
          reticle.visible = true;
          reticle.matrix.fromArray(pose.transform.matrix);
        } else {
          reticle.visible = false;
        }
      }
      renderer.render(scene, camera);
    });
  </script>
</body>
</html>
