<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>AR Video Projection</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
      body { margin: 0; overflow: hidden; }
      #overlay { position: fixed; top: 0; left: 0; pointer-events: none; width: 100%; height: 100%; background: transparent; }
    </style>
  </head>
  <body>
    <!-- Hidden video element that will be used as a texture -->
    <video id="srcVideo" src="./video/123.mp4" loop playsinline style="display:none"></video>

    <script type="module">
      import * as THREE from 'https://unpkg.com/three@0.160.0/build/three.module.js';
      import { ARButton } from 'https://unpkg.com/three@0.160.0/examples/jsm/webxr/ARButton.js';

      // Set up renderer with alpha so the real‑world camera view shows through.
      const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      // Create an "Enter AR" button and request hit‑test capability so we can place the plane on real‑world surfaces.
      document.body.appendChild(ARButton.createButton(renderer, { requiredFeatures: ['hit-test'] }));

      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera();

      // Wait for the video metadata so we know its dimensions.
      const video = document.getElementById('srcVideo');
      await video.play();

      const texture = new THREE.VideoTexture(video);
      texture.encoding = THREE.sRGBEncoding;
      texture.minFilter = THREE.LinearFilter;
      texture.magFilter = THREE.LinearFilter;

      // Make a plane that matches the video's aspect ratio (width = 1 unit).
      const aspect = video.videoHeight / video.videoWidth;
      const geometry = new THREE.PlaneGeometry(1, aspect);
      const material = new THREE.MeshBasicMaterial({ map: texture, side: THREE.DoubleSide });
      const videoPlane = new THREE.Mesh(geometry, material);
      videoPlane.visible = false;   // only show after first hit‑test
      scene.add(videoPlane);

      // WebXR hit‑testing setup so we can place the video where the user taps.
      let hitTestSource = null;
      let localReferenceSpace = null;
      renderer.xr.addEventListener('sessionstart', async () => {
        const session = renderer.xr.getSession();
        const viewerSpace = await session.requestReferenceSpace('viewer');
        hitTestSource = await session.requestHitTestSource({ space: viewerSpace });
        localReferenceSpace = await session.requestReferenceSpace('local');
      });

      // Each frame: look for a real‑world surface underneath the reticle, then stick the plane to it.
      renderer.setAnimationLoop((timestamp, frame) => {
        if (frame && hitTestSource) {
          const hits = frame.getHitTestResults(hitTestSource);
          if (hits.length) {
            const hit = hits[0];
            const pose = hit.getPose(localReferenceSpace);
            if (!videoPlane.visible) videoPlane.visible = true;
            videoPlane.position.set(pose.transform.position.x, pose.transform.position.y, pose.transform.position.z);
            videoPlane.quaternion.set(pose.transform.orientation.x, pose.transform.orientation.y, pose.transform.orientation.z, pose.transform.orientation.w);
          }
        }
        renderer.render(scene, camera);
      });

      // Keep full‑screen canvas in sync when the phone rotates.
      window.addEventListener('resize', () => {
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    </script>
  </body>
</html>
